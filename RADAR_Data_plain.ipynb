{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WVcsTxSUzrHm"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OZj8GcYqCCk8",
    "outputId": "bdbc6634-b63b-40cc-d3c7-a177c853fe38"
   },
   "outputs": [],
   "source": [
    "tasks = 12\n",
    "epochs = 100\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "on_colab = False\n",
    "divide_tasks = False\n",
    "\n",
    "category={0: 'boxingmoving', \n",
    "          1: 'boxingstill', \n",
    "          2: 'crawling', \n",
    "          3: 'running', \n",
    "          4: 'still', \n",
    "          5: 'walking', \n",
    "          6: 'walkinglow'}\n",
    "\n",
    "cuda_available = False\n",
    "if torch.cuda.is_available():\n",
    "    cuda_available = True\n",
    "\n",
    "dt = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zpUUFFhoUlMJ"
   },
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "colab_type": "code",
    "id": "ZTSQX1mHCLnl",
    "outputId": "bef60efe-469d-42f7-de9a-8d8fce63ffbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 7, 9, 128, 128])\n",
      "torch.Size([12, 7, 3, 128, 128])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 3])\n"
     ]
    }
   ],
   "source": [
    "### Data: (# of subject, # of classes, # of data, width, height)\n",
    "if divide_tasks:\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "\n",
    "    for task in range(1, tasks+1):\n",
    "        if on_colab:\n",
    "            data_path = 'drive/My Drive/projects/data/RADAR/Subject%d'%(task)\n",
    "        else:\n",
    "            data_path = './data/RADAR/Subject%d'%(task)\n",
    "\n",
    "        train_data_per_task = []\n",
    "        test_data_per_task = []\n",
    "        for _, cat in category.items():\n",
    "            # train data\n",
    "            train_data_per_cat = []\n",
    "            test_data_per_cat = []\n",
    "\n",
    "            for i in range(1, 10):\n",
    "                filename = 'Human_Spect_test%d_%s_0%d.png'%(task, cat, i)\n",
    "                file_path = os.path.join(data_path, 'train', cat, filename)\n",
    "                img = Image.open(file_path)\n",
    "                img.load()\n",
    "                img = np.array(img)\n",
    "                train_data_per_cat.append(img)\n",
    "\n",
    "            # test data\n",
    "            for i in range(10, 13):\n",
    "                filename = 'Human_Spect_test%d_%s_%d.png'%(task, cat, i)\n",
    "                file_path = os.path.join(data_path, 'test', cat, filename)\n",
    "                img = Image.open(file_path)\n",
    "                img.load()\n",
    "                img = np.array(img)\n",
    "                test_data_per_cat.append(img)\n",
    "\n",
    "            \n",
    "            train_data_per_task.append(train_data_per_cat)\n",
    "            test_data_per_task.append(test_data_per_cat)\n",
    "            \n",
    "        train_data.append(train_data_per_task)\n",
    "        test_data.append(test_data_per_task)\n",
    "        \n",
    "\n",
    "    train_data = torch.Tensor(train_data)\n",
    "    test_data = torch.Tensor(test_data)\n",
    "\n",
    "    if cuda_available:\n",
    "        train_data = train_data.cuda()\n",
    "        test_data = test_data.cuda()\n",
    "\n",
    "    print(train_data.shape)\n",
    "    print(test_data.shape)\n",
    "\n",
    "    train_labels = np.zeros((9, ))\n",
    "    test_labels = np.zeros((3, ))\n",
    "\n",
    "    for i in range(1, 7):\n",
    "        train_labels = np.vstack((train_labels, np.zeros((9, )) + i))\n",
    "        test_labels = np.vstack((test_labels, np.zeros((3, )) + i))\n",
    "\n",
    "    train_labels = torch.Tensor(train_labels).type(torch.LongTensor)\n",
    "    test_labels = torch.Tensor(test_labels).type(torch.LongTensor)\n",
    "\n",
    "    if cuda_available:\n",
    "        train_labels = train_labels.cuda()\n",
    "        test_labels = test_labels.cuda()\n",
    "\n",
    "    print(train_labels.shape)\n",
    "    print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ExSwX8psD3eH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 108, 128, 128])\n",
      "torch.Size([7, 36, 128, 128])\n",
      "torch.Size([7, 108])\n",
      "torch.Size([7, 36])\n"
     ]
    }
   ],
   "source": [
    "if not divide_tasks:\n",
    "    train_data = torch.empty((7, 108, 128, 128))\n",
    "    test_data = torch.empty((7, 36, 128, 128))\n",
    "\n",
    "    for task in range(1, tasks+1):\n",
    "        if on_colab:\n",
    "            data_path = 'drive/My Drive/projects/data/RADAR/Subject%d'%(task)\n",
    "        else:\n",
    "            data_path = './data/RADAR/Subject%d'%(task)\n",
    "\n",
    "        for cat_i, cat in category.items():\n",
    "            # train data\n",
    "            for i in range(1, 10):\n",
    "                filename = 'Human_Spect_test%d_%s_0%d.png'%(task, cat, i)\n",
    "                file_path = os.path.join(data_path, 'train', cat, filename)\n",
    "                img = Image.open(file_path)\n",
    "                img.load()\n",
    "                img = np.array(img)\n",
    "                train_data[cat_i, (task - 1) * 9 + (i - 1)] = torch.Tensor(img)\n",
    "\n",
    "            # test data\n",
    "            for i in range(10, 13):\n",
    "                filename = 'Human_Spect_test%d_%s_%d.png'%(task, cat, i)\n",
    "                file_path = os.path.join(data_path, 'test', cat, filename)\n",
    "                img = Image.open(file_path)\n",
    "                img.load()\n",
    "                img = np.array(img)\n",
    "                test_data[cat_i, (task - 1) * 3 + (i - 10)] = torch.tensor(img)\n",
    "\n",
    "    if cuda_available:\n",
    "        train_data = train_data.cuda()\n",
    "        test_data = test_data.cuda()\n",
    "\n",
    "    print(train_data.shape)\n",
    "    print(test_data.shape)\n",
    "    \n",
    "    train_labels = np.zeros((9*12, ))\n",
    "    test_labels = np.zeros((3*12, ))\n",
    "\n",
    "    for i in range(1, 7):\n",
    "        train_labels = np.vstack((train_labels, np.zeros((9*12, )) + i))\n",
    "        test_labels = np.vstack((test_labels, np.zeros((3*12, )) + i))\n",
    "\n",
    "    train_labels = torch.Tensor(train_labels).type(torch.LongTensor)\n",
    "    test_labels = torch.Tensor(test_labels).type(torch.LongTensor)\n",
    "\n",
    "    if cuda_available:\n",
    "        train_labels = train_labels.cuda()\n",
    "        test_labels = test_labels.cuda()\n",
    "\n",
    "    print(train_labels.shape)\n",
    "    print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.conv_module = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 6, 5, 1), # 6 @ 124*124\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2), # 6 @ 62*62\n",
    "            torch.nn.Conv2d(6, 16, 7, 1), # 16 @ 56*56\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2), # 16 @ 28*28\n",
    "            # Conv 추가\n",
    "            torch.nn.Conv2d(16, 16, 5, 1), # 16 @ 24*24\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2) # 16 @ 12*12\n",
    "        )\n",
    "\n",
    "        self.fc_module = torch.nn.Sequential(\n",
    "            torch.nn.Linear(16*12*12, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            #Linear 빼고\n",
    "            #dropout 추가\n",
    "            torch.nn.Dropout(p=0.3),\n",
    "            torch.nn.Linear(128, 7)\n",
    "        )\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.conv_module = self.conv_module.cuda()\n",
    "            self.fc_module = self.fc_module.cuda()\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.conv_module(input)\n",
    "        dim = x.shape[1] * x.shape[2] * x.shape[3]\n",
    "        x = x.view(-1, dim)\n",
    "        return self.fc_module(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1igJtxnxi0QE"
   },
   "source": [
    "### Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 7, 9, 128, 128])\n",
      "torch.Size([12, 7, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nvhvOVdcirjz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, AVG. loss: 203.865\n",
      "\n",
      "Epoch: 10, AVG. loss: 35.756\n",
      "\n",
      "Epoch: 15, AVG. loss: 18.652\n",
      "\n",
      "Epoch: 20, AVG. loss: 16.232\n",
      "\n",
      "Epoch: 25, AVG. loss: 7.644\n",
      "\n",
      "Epoch: 30, AVG. loss: 4.977\n",
      "\n",
      "Epoch: 35, AVG. loss: 4.378\n",
      "\n",
      "Epoch: 40, AVG. loss: 2.465\n",
      "\n",
      "Epoch: 45, AVG. loss: 1.512\n",
      "\n",
      "Epoch: 50, AVG. loss: 7.597\n",
      "\n",
      "Epoch: 55, AVG. loss: 7.219\n",
      "\n",
      "Epoch: 60, AVG. loss: 2.325\n",
      "\n",
      "Epoch: 65, AVG. loss: 1.267\n",
      "\n",
      "Epoch: 70, AVG. loss: 0.631\n",
      "\n",
      "Epoch: 75, AVG. loss: 0.780\n",
      "\n",
      "Epoch: 80, AVG. loss: 0.536\n",
      "\n",
      "Epoch: 85, AVG. loss: 0.276\n",
      "\n",
      "Epoch: 90, AVG. loss: 0.290\n",
      "\n",
      "Epoch: 95, AVG. loss: 0.147\n",
      "\n",
      "Epoch: 100, AVG. loss: 0.162\n",
      "\n",
      "Average accuracy 94 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = NeuralNet()\n",
    "if cuda_available:\n",
    "    net = net.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "logfile_name = \"logfile_training_%d_%d_%d_%d_%d.txt\" % (dt.year, dt.month, dt.day, dt.hour, dt.minute)\n",
    "log_file = open(logfile_name, \"w\")\n",
    "\n",
    "running_loss = 0\n",
    "avg_acc = {}\n",
    "\n",
    "net.train()\n",
    "for epoch in range(epochs):\n",
    "    for key, _ in category.items():\n",
    "        _train_data = train_data[key].view(9*12, 1, 128, 128)\n",
    "        _train_label = train_labels[key]\n",
    "        #print(_train_data.shape)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(_train_data)\n",
    "        loss = criterion(outputs, _train_label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.data.item()\n",
    "\n",
    "    if epoch % 5 == 4:\n",
    "        msg = 'Epoch: %d, AVG. loss: %.3f\\n'% (epoch + 1, running_loss)\n",
    "        print(msg)\n",
    "        log_file.write(msg)\n",
    "        running_loss = 0\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "net.eval()\n",
    "for key, _ in category.items():\n",
    "    _test_data = test_data[key].view(3*12, 1, 128, 128)\n",
    "    output = net(_test_data)\n",
    "    _, predicted = torch.max(output.data, dim=1)\n",
    "    total += test_labels[key].shape[0]\n",
    "    correct += (predicted == test_labels[key]).sum()\n",
    "        \n",
    "acc = correct.cpu().numpy()*100/total\n",
    "msg = 'Average accuracy %d %%\\n' % (acc)\n",
    "print(msg)\n",
    "log_file.write(msg)\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dnyUm1g6i18h"
   },
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GuThumwmir6U"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"# of tasks\")\n",
    "plt.ylabel(\"Avg. acc\")\n",
    "plt.title(\"Average Accuracies\")\n",
    "\n",
    "x, y = list(avg_acc.keys()), list(avg_acc.values())\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RADAR_Data_plain.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
