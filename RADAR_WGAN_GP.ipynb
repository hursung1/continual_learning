{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RADAR_WGAN_GP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVcsTxSUzrHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZj8GcYqCCk8",
        "colab_type": "code",
        "outputId": "a3e55148-23c2-4160-efd3-6d02ba74d6af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i48x5D0zL2O",
        "colab_type": "text"
      },
      "source": [
        "### DGR Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljlZk-pZzOg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator_Conv(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Generator Class for GAN\n",
        "    \"\"\"\n",
        "    def __init__(self, input_node_size, output_shape, hidden_node_size=256,\n",
        "                    hidden_node_num=3):\n",
        "        \"\"\"\n",
        "        input_node_size: dimension of latent vector\n",
        "        output_shape: dimension of output image\n",
        "        \"\"\"\n",
        "        super(Generator_Conv, self).__init__()\n",
        "\n",
        "        self.input_node_size = input_node_size\n",
        "        self.output_shape = output_shape\n",
        "        num_channels, width, _ = output_shape\n",
        "\n",
        "        layer_channels = []\n",
        "#         if width <= 32:\n",
        "        layer_channels.append(width//2)\n",
        "        layer_channels.append(width//4)\n",
        "\n",
        "        conv2d_1 = torch.nn.ConvTranspose2d(in_channels=input_node_size,\n",
        "                                   out_channels=width*4, \n",
        "                                   kernel_size=layer_channels[1], \n",
        "                                   stride=1,\n",
        "                                   padding=0,\n",
        "                                   bias=False)\n",
        "        conv2d_2 = torch.nn.ConvTranspose2d(in_channels=width*4, \n",
        "                                   out_channels=width*2, \n",
        "                                   kernel_size=4, \n",
        "                                   stride=2,\n",
        "                                   padding=1,\n",
        "                                   bias=False)\n",
        "        conv2d_3 = torch.nn.ConvTranspose2d(in_channels=width*2, \n",
        "                                   out_channels=num_channels, \n",
        "                                   kernel_size=4, \n",
        "                                   stride=2,\n",
        "                                   padding=1,\n",
        "                                   bias=False)\n",
        "\n",
        "        self.network = torch.nn.Sequential(\n",
        "            conv2d_1,\n",
        "            torch.nn.BatchNorm2d(num_features = width*4),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            conv2d_2,\n",
        "            torch.nn.BatchNorm2d(num_features = width*2),\n",
        "            torch.nn.ReLU(inplace=True),\n",
        "            conv2d_3,\n",
        "            torch.nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        _x = x.view(-1, self.input_node_size, 1, 1)\n",
        "        return self.network(_x)\n",
        "    \n",
        "    \n",
        "class Discriminator_Conv(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Discriminator Class for GAN\n",
        "    \"\"\"\n",
        "    def __init__(self, input_shape, hidden_node_size=256, output_node_size=1):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_shape: (C, W, H)\n",
        "\n",
        "        \"\"\"\n",
        "        super(Discriminator_Conv, self).__init__()\n",
        "        num_channels, width, _ = input_shape\n",
        "\n",
        "        conv2d_1 = torch.nn.Conv2d(in_channels=num_channels, \n",
        "                                   out_channels=width*2, \n",
        "                                   kernel_size=4, \n",
        "                                   stride=2,\n",
        "                                   padding=1,\n",
        "                                   bias=False)\n",
        "        conv2d_2 = torch.nn.Conv2d(in_channels=width*2, \n",
        "                                   out_channels=width*4, \n",
        "                                   kernel_size=4, \n",
        "                                   stride=2,\n",
        "                                   padding=1,\n",
        "                                   bias=False)\n",
        "        conv2d_3 = torch.nn.Conv2d(in_channels=width*4, \n",
        "                                   out_channels=output_node_size, \n",
        "                                   kernel_size=7, \n",
        "                                   stride=1,\n",
        "                                   padding=0,\n",
        "                                   bias=False)\n",
        "\n",
        "        self.network = torch.nn.Sequential(\n",
        "            conv2d_1,\n",
        "            torch.nn.BatchNorm2d(num_features=width*2),\n",
        "            torch.nn.LeakyReLU(inplace=True),\n",
        "            conv2d_2,\n",
        "            torch.nn.BatchNorm2d(num_features=width*4),\n",
        "            torch.nn.LeakyReLU(inplace=True),\n",
        "            conv2d_3,\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x).view(-1, 1)\n",
        "\n",
        "    \n",
        "class Solver(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Solver Class for Deep Generative Replay\n",
        "    \"\"\"\n",
        "    def __init__(self, input_data_shape, T_n):\n",
        "        assert len(input_data_shape) == 3\n",
        "\n",
        "        super(Solver, self).__init__()\n",
        "        num_channels, width, height = input_data_shape\n",
        "        fc1 = torch.nn.Linear(num_channels*width*height, 128)\n",
        "        fc2 = torch.nn.Linear(128, 256)\n",
        "        fc3 = torch.nn.Linear(256, T_n)\n",
        "        self.network = torch.nn.Sequential(\n",
        "            fc1,\n",
        "            torch.nn.ReLU(),\n",
        "            fc2,\n",
        "            torch.nn.ReLU(),\n",
        "            fc3\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x.view(x.shape[0], -1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpUUFFhoUlMJ",
        "colab_type": "text"
      },
      "source": [
        "### Set Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCp93jkFF82k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_shape = (1, 128, 128)\n",
        "num_noise = batch_size = 64\n",
        "epochs = 200\n",
        "ld = 10\n",
        "tasks = 12\n",
        "\n",
        "on_colab = True\n",
        "divide_tasks = True\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "category={0: 'boxingmoving', \n",
        "          1: 'boxingstill', \n",
        "          2: 'crawling', \n",
        "          3: 'running', \n",
        "          4: 'still', \n",
        "          5: 'walking', \n",
        "          6: 'walkinglow'}\n",
        "\n",
        "dt = datetime.datetime.now()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoMzUcrXGBXV",
        "colab_type": "text"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTSQX1mHCLnl",
        "colab_type": "code",
        "outputId": "93982817-7934-47db-d3a5-3933f774b65a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "train_data = []\n",
        "test_data = []\n",
        "\n",
        "for task in range(1, tasks+1):\n",
        "    if on_colab:\n",
        "        data_path = 'drive/My Drive/projects/data/RADAR/Subject%d'%(task)\n",
        "    else:\n",
        "        data_path = './data/RADAR/Subject%d'%(task)\n",
        "\n",
        "    train_data_per_task = []\n",
        "    test_data_per_task = []\n",
        "    for _, cat in category.items():\n",
        "        # train data\n",
        "        train_data_per_cat = []\n",
        "        test_data_per_cat = []\n",
        "\n",
        "        for i in range(1, 10):\n",
        "            filename = 'Human_Spect_test%d_%s_0%d.png'%(task, cat, i)\n",
        "            file_path = os.path.join(data_path, 'train', cat, filename)\n",
        "            img = Image.open(file_path)\n",
        "            img.load()\n",
        "            img = np.array(img)\n",
        "            train_data_per_cat.append(img)\n",
        "\n",
        "        # test data\n",
        "        for i in range(10, 13):\n",
        "            filename = 'Human_Spect_test%d_%s_%d.png'%(task, cat, i)\n",
        "            file_path = os.path.join(data_path, 'test', cat, filename)\n",
        "            img = Image.open(file_path)\n",
        "            img.load()\n",
        "            img = np.array(img)\n",
        "            test_data_per_cat.append(img)\n",
        "\n",
        "        \n",
        "        train_data_per_task.append(train_data_per_cat)\n",
        "        test_data_per_task.append(test_data_per_cat)\n",
        "        \n",
        "    train_data.append(train_data_per_task)\n",
        "    test_data.append(test_data_per_task)\n",
        "    \n",
        "\n",
        "train_data = torch.Tensor(train_data).to(device)\n",
        "test_data = torch.Tensor(test_data).to(device)\n",
        "\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)\n",
        "\n",
        "train_labels = np.zeros((9, ))\n",
        "test_labels = np.zeros((3, ))\n",
        "\n",
        "for i in range(1, 7):\n",
        "    train_labels = np.vstack((train_labels, np.zeros((9, )) + i))\n",
        "    test_labels = np.vstack((test_labels, np.zeros((3, )) + i))\n",
        "\n",
        "train_labels = torch.Tensor(train_labels).type(torch.LongTensor).to(device)\n",
        "test_labels = torch.Tensor(test_labels).type(torch.LongTensor).to(device)\n",
        "\n",
        "print(train_labels.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([12, 7, 9, 128, 128])\n",
            "torch.Size([12, 7, 3, 128, 128])\n",
            "torch.Size([7, 9])\n",
            "torch.Size([7, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIRpb0lDzkJY",
        "colab_type": "text"
      },
      "source": [
        "### Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExSwX8psD3eH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_noise(batch_size, N_noise, device='cpu'):\n",
        "    \"\"\"\n",
        "    Returns \n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available() and device == 'cpu':\n",
        "        device='cuda:0'\n",
        "    \n",
        "    return torch.randn(batch_size, N_noise).to(device)\n",
        "\n",
        "\n",
        "def init_params(model):\n",
        "    \"\"\"\n",
        "    initiallize network's parameter\n",
        "    \"\"\"\n",
        "    for p in model.parameters():\n",
        "        if(p.dim() > 1):\n",
        "            torch.nn.init.xavier_normal_(p)\n",
        "        else:\n",
        "            torch.nn.init.uniform_(p, 0.1, 0.2)\n",
        "            \n",
        "            \n",
        "def tensor_normalize(tensor):\n",
        "    \"\"\"\n",
        "    Normalize tensor to [-1, 1]\n",
        "    \"\"\"\n",
        "    _tensor = tensor.detach().clone()\n",
        "    _tensor_each_sum = _tensor.sum(dim=1)\n",
        "    _tensor /= _tensor_each_sum.unsqueeze(1)\n",
        "\n",
        "    _tensor[torch.isnan(_tensor)] = 0.0\n",
        "    _tensor = 2*_tensor - 1\n",
        "    return _tensor\n",
        "\n",
        "\n",
        "def model_grad_switch(net, requires_grad):\n",
        "    \"\"\"\n",
        "    switch network's requires_grad\n",
        "    \"\"\"\n",
        "    for params in net.parameters():\n",
        "        params.requires_grad_(requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1igJtxnxi0QE",
        "colab_type": "text"
      },
      "source": [
        "### Training & Validate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvhvOVdcirjz",
        "colab_type": "code",
        "outputId": "2f00fc02-d845-4ca3-dda2-7e2833f8cf77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_data = tensor_normalize(train_data)\n",
        "train_labels = tensor_normalize(train_labels)\n",
        "test_data = tensor_normalize(test_data)\n",
        "test_labels = tensor_normalize(test_labels)\n",
        "\n",
        "gen = Generator_Conv(input_node_size=num_noise, output_shape=data_shape).to(device)\n",
        "disc = Discriminator_Conv(input_shape=data_shape).to(device)\n",
        "\n",
        "init_params(gen)\n",
        "init_params(disc)\n",
        "\n",
        "optim_g = torch.optim.Adam(gen.parameters(), lr=1e-3, betas=(0, 0.9))\n",
        "optim_d = torch.optim.Adam(disc.parameters(), lr=1e-3, betas=(0, 0.9))\n",
        "\n",
        "#logfile_name = \"logfile_training_%d_%d_%d_%d_%d.txt\" % (dt.year, dt.month, dt.day, dt.hour, dt.minute)\n",
        "#log_file = open(logfile_name, \"w\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    gen.train()\n",
        "    disc.train()\n",
        "\n",
        "    for i in range(10):\n",
        "        for _train_data in train_data:\n",
        "            x = _train_data.view(-1, 1, 128, 128).to(device)\n",
        "            num_data = x.shape[0]\n",
        "            noise = sample_noise(num_data, num_noise).to(device)\n",
        "\n",
        "            x_g = gen(noise)\n",
        "\n",
        "            ### Discriminator train\n",
        "            optim_d.zero_grad()\n",
        "\n",
        "            ## Regularization Term\n",
        "            eps = torch.rand(1).item()\n",
        "            x_hat = (x.detach().clone() * eps + x_g.detach().clone() * (1 - eps)).requires_grad_(True)\n",
        "\n",
        "            loss_xhat = disc(x_hat)\n",
        "            fake = torch.ones(loss_xhat.shape[0], 1).requires_grad_(False).to(device)\n",
        "\n",
        "            gradients = torch.autograd.grad(\n",
        "                outputs = loss_xhat,\n",
        "                inputs = x_hat,\n",
        "                grad_outputs=fake,\n",
        "                create_graph = True,\n",
        "                retain_graph = True,\n",
        "                only_inputs = True\n",
        "            )[0]\n",
        "            gradients = gradients.view(gradients.shape[0], -1)\n",
        "            gp = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * ld\n",
        "\n",
        "            p_real = disc(x)\n",
        "            p_fake = disc(x_g.detach())\n",
        "\n",
        "            loss_d = torch.mean(p_fake) - torch.mean(p_real) + gp\n",
        "            loss_d.backward()\n",
        "            optim_d.step()\n",
        "\n",
        "            if i % 5 == 4:\n",
        "                ### Generator train\n",
        "                optim_g.zero_grad()\n",
        "                p_fake = disc(x_g)\n",
        "                loss_g = -torch.mean(p_fake)\n",
        "                loss_g.backward()\n",
        "                optim_g.step()\n",
        "                \n",
        "    print(\"[Epoch %d/%d] [D loss: %f] [G loss: %f]\" % (epoch, epochs, loss_d.item(), loss_g.item()))\n",
        "\n",
        "    if epoch % 10 == 9:\n",
        "        dir_name = \"imgs/\"#Task_%d\" % (t+1)\n",
        "        if not os.path.isdir(dir_name):\n",
        "            os.mkdir(dir_name)\n",
        "            \n",
        "        gen.eval()\n",
        "        noise = sample_noise(64, num_noise).to(device)\n",
        "\n",
        "        gen_img = gen(noise)\n",
        "        torchvision.utils.save_image(gen_img, 'imgs/%03d.png'%(epoch+1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 0/200] [D loss: 3.337783] [G loss: -0.995154]\n",
            "[Epoch 1/200] [D loss: 9.916254] [G loss: -0.999929]\n",
            "[Epoch 2/200] [D loss: 9.964005] [G loss: -0.999994]\n",
            "[Epoch 3/200] [D loss: 9.998698] [G loss: -0.999999]\n",
            "[Epoch 4/200] [D loss: 9.992407] [G loss: -0.999996]\n",
            "[Epoch 5/200] [D loss: 9.999735] [G loss: -1.000000]\n",
            "[Epoch 6/200] [D loss: 10.000000] [G loss: -1.000000]\n",
            "[Epoch 7/200] [D loss: 10.000000] [G loss: -1.000000]\n",
            "[Epoch 8/200] [D loss: 9.899141] [G loss: -0.999999]\n",
            "[Epoch 9/200] [D loss: 9.999899] [G loss: -1.000000]\n",
            "[Epoch 10/200] [D loss: 9.975981] [G loss: -0.999999]\n",
            "[Epoch 11/200] [D loss: 9.999255] [G loss: -1.000000]\n",
            "[Epoch 12/200] [D loss: 9.857988] [G loss: -1.000000]\n",
            "[Epoch 13/200] [D loss: 9.999991] [G loss: -1.000000]\n",
            "[Epoch 14/200] [D loss: 6.318378] [G loss: -0.998781]\n",
            "[Epoch 15/200] [D loss: 3.045955] [G loss: -0.999559]\n",
            "[Epoch 16/200] [D loss: 7.618859] [G loss: -0.999484]\n",
            "[Epoch 17/200] [D loss: 0.237737] [G loss: -0.999884]\n",
            "[Epoch 18/200] [D loss: 1.839489] [G loss: -0.962659]\n",
            "[Epoch 19/200] [D loss: 0.448214] [G loss: -0.985566]\n",
            "[Epoch 20/200] [D loss: 1.726425] [G loss: -0.998328]\n",
            "[Epoch 21/200] [D loss: 0.072458] [G loss: -0.989883]\n",
            "[Epoch 22/200] [D loss: 0.331321] [G loss: -0.983999]\n",
            "[Epoch 23/200] [D loss: 0.063000] [G loss: -0.985439]\n",
            "[Epoch 24/200] [D loss: 0.128349] [G loss: -0.979616]\n",
            "[Epoch 25/200] [D loss: 0.126572] [G loss: -0.979782]\n",
            "[Epoch 26/200] [D loss: 0.468757] [G loss: -0.985587]\n",
            "[Epoch 27/200] [D loss: 0.116283] [G loss: -0.982565]\n",
            "[Epoch 28/200] [D loss: 1.258473] [G loss: -0.985681]\n",
            "[Epoch 29/200] [D loss: 0.262441] [G loss: -0.968126]\n",
            "[Epoch 30/200] [D loss: 2.842123] [G loss: -0.702484]\n",
            "[Epoch 31/200] [D loss: 0.297143] [G loss: -0.978803]\n",
            "[Epoch 32/200] [D loss: 0.046335] [G loss: -0.974715]\n",
            "[Epoch 33/200] [D loss: 0.842856] [G loss: -0.978305]\n",
            "[Epoch 34/200] [D loss: 0.111774] [G loss: -0.986777]\n",
            "[Epoch 35/200] [D loss: 0.108518] [G loss: -0.976852]\n",
            "[Epoch 36/200] [D loss: 0.082915] [G loss: -0.990653]\n",
            "[Epoch 37/200] [D loss: 0.181503] [G loss: -0.980259]\n",
            "[Epoch 38/200] [D loss: 0.294426] [G loss: -0.970914]\n",
            "[Epoch 39/200] [D loss: 0.073737] [G loss: -0.978452]\n",
            "[Epoch 40/200] [D loss: 0.153979] [G loss: -0.983133]\n",
            "[Epoch 41/200] [D loss: 0.021582] [G loss: -0.987900]\n",
            "[Epoch 42/200] [D loss: 0.047914] [G loss: -0.971887]\n",
            "[Epoch 43/200] [D loss: 0.017946] [G loss: -0.980073]\n",
            "[Epoch 44/200] [D loss: 0.178687] [G loss: -0.970181]\n",
            "[Epoch 45/200] [D loss: 0.031848] [G loss: -0.973651]\n",
            "[Epoch 46/200] [D loss: 0.056349] [G loss: -0.945135]\n",
            "[Epoch 47/200] [D loss: 0.021937] [G loss: -0.980675]\n",
            "[Epoch 48/200] [D loss: 0.357726] [G loss: -0.955202]\n",
            "[Epoch 49/200] [D loss: 0.079480] [G loss: -0.985982]\n",
            "[Epoch 50/200] [D loss: 0.107192] [G loss: -0.982143]\n",
            "[Epoch 51/200] [D loss: 0.017732] [G loss: -0.984452]\n",
            "[Epoch 52/200] [D loss: 0.078817] [G loss: -0.990222]\n",
            "[Epoch 53/200] [D loss: 0.342905] [G loss: -0.976602]\n",
            "[Epoch 54/200] [D loss: 0.017376] [G loss: -0.988044]\n",
            "[Epoch 55/200] [D loss: 0.221895] [G loss: -0.975582]\n",
            "[Epoch 56/200] [D loss: 0.043877] [G loss: -0.980504]\n",
            "[Epoch 57/200] [D loss: 0.156553] [G loss: -0.975949]\n",
            "[Epoch 58/200] [D loss: 0.044375] [G loss: -0.987150]\n",
            "[Epoch 59/200] [D loss: 0.048111] [G loss: -0.978000]\n",
            "[Epoch 60/200] [D loss: 0.068489] [G loss: -0.982355]\n",
            "[Epoch 61/200] [D loss: 0.025307] [G loss: -0.983297]\n",
            "[Epoch 62/200] [D loss: 0.190006] [G loss: -0.979758]\n",
            "[Epoch 63/200] [D loss: 0.021441] [G loss: -0.986172]\n",
            "[Epoch 64/200] [D loss: 0.043142] [G loss: -0.963967]\n",
            "[Epoch 65/200] [D loss: 0.046250] [G loss: -0.979946]\n",
            "[Epoch 66/200] [D loss: 0.064901] [G loss: -0.983631]\n",
            "[Epoch 67/200] [D loss: 0.013988] [G loss: -0.983311]\n",
            "[Epoch 68/200] [D loss: 0.037528] [G loss: -0.984598]\n",
            "[Epoch 69/200] [D loss: 0.019801] [G loss: -0.990839]\n",
            "[Epoch 70/200] [D loss: 0.023986] [G loss: -0.980099]\n",
            "[Epoch 71/200] [D loss: 0.029773] [G loss: -0.985443]\n",
            "[Epoch 72/200] [D loss: 0.047948] [G loss: -0.979168]\n",
            "[Epoch 73/200] [D loss: 0.040518] [G loss: -0.987887]\n",
            "[Epoch 74/200] [D loss: 0.047910] [G loss: -0.969143]\n",
            "[Epoch 75/200] [D loss: 0.012678] [G loss: -0.983863]\n",
            "[Epoch 76/200] [D loss: 0.014021] [G loss: -0.982313]\n",
            "[Epoch 77/200] [D loss: 0.020466] [G loss: -0.978545]\n",
            "[Epoch 78/200] [D loss: 0.019729] [G loss: -0.981292]\n",
            "[Epoch 79/200] [D loss: 0.106983] [G loss: -0.969881]\n",
            "[Epoch 80/200] [D loss: 0.026521] [G loss: -0.984416]\n",
            "[Epoch 81/200] [D loss: 0.020618] [G loss: -0.980362]\n",
            "[Epoch 82/200] [D loss: 0.011485] [G loss: -0.980921]\n",
            "[Epoch 83/200] [D loss: 0.303563] [G loss: -0.990689]\n",
            "[Epoch 84/200] [D loss: 0.063345] [G loss: -0.975717]\n",
            "[Epoch 85/200] [D loss: 0.050248] [G loss: -0.976000]\n",
            "[Epoch 86/200] [D loss: 0.059051] [G loss: -0.982811]\n",
            "[Epoch 87/200] [D loss: 0.018299] [G loss: -0.983626]\n",
            "[Epoch 88/200] [D loss: 0.052348] [G loss: -0.982036]\n",
            "[Epoch 89/200] [D loss: 0.087362] [G loss: -0.982396]\n",
            "[Epoch 90/200] [D loss: 0.026364] [G loss: -0.985776]\n",
            "[Epoch 91/200] [D loss: 0.017816] [G loss: -0.979707]\n",
            "[Epoch 92/200] [D loss: 0.012266] [G loss: -0.980563]\n",
            "[Epoch 93/200] [D loss: 0.060863] [G loss: -0.982458]\n",
            "[Epoch 94/200] [D loss: 0.019128] [G loss: -0.984202]\n",
            "[Epoch 95/200] [D loss: 0.011427] [G loss: -0.987556]\n",
            "[Epoch 96/200] [D loss: 0.030740] [G loss: -0.982078]\n",
            "[Epoch 97/200] [D loss: 0.013793] [G loss: -0.980549]\n",
            "[Epoch 98/200] [D loss: 0.019164] [G loss: -0.981850]\n",
            "[Epoch 99/200] [D loss: 0.022151] [G loss: -0.983570]\n",
            "[Epoch 100/200] [D loss: 0.078106] [G loss: -0.982071]\n",
            "[Epoch 101/200] [D loss: 0.030667] [G loss: -0.984259]\n",
            "[Epoch 102/200] [D loss: 0.026107] [G loss: -0.979042]\n",
            "[Epoch 103/200] [D loss: 0.122183] [G loss: -0.970984]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnyUm1g6i18h",
        "colab_type": "text"
      },
      "source": [
        "### Visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuThumwmir6U",
        "colab_type": "code",
        "outputId": "006c54d8-a6ef-426c-8048-94c2e2681968",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.xlabel(\"# of tasks\")\n",
        "plt.ylabel(\"Avg. acc\")\n",
        "plt.title(\"Average Accuracies\")\n",
        "\n",
        "x, y = list(avg_acc.keys()), list(avg_acc.values())\n",
        "plt.plot(x, y)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSikVYDTxK6VUgNHEr5RSAeb/A94rVcC8gncXAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjpfQlEEtHyB",
        "colab_type": "text"
      },
      "source": [
        "### Without task dividing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fihWtNi_dNb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = NeuralNet()\n",
        "if cuda_available:\n",
        "    net = net.cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "logfile_name = \"logfile_training_%d_%d_%d_%d_%d.txt\" % (dt.year, dt.month, dt.day, dt.hour, dt.minute)\n",
        "log_file = open(logfile_name, \"w\")\n",
        "\n",
        "running_loss = 0\n",
        "avg_acc = {}\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for key, _ in category.items():\n",
        "        _train_data = train_data[key].view(9, 1, 128, 128)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(_train_data)\n",
        "        loss = criterion(outputs, train_labels[key])\n",
        "    \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "        running_loss += loss.data.item()\n",
        "\n",
        "    if epoch % 5 == 4:\n",
        "        msg = '[%d\\t%d] AVG. loss: %.3f\\n'% (task+1, epoch + 1, running_loss)\n",
        "        print(msg)\n",
        "        log_file.write(msg)\n",
        "        running_loss = 0\n",
        "\n",
        "each_task_acc = np.array([])\n",
        "for j in range(task+1):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for key, _ in category.items():\n",
        "        _test_data = test_data[j, key].view(3, 1, 128, 128)\n",
        "        output = net(_test_data)\n",
        "        _, predicted = torch.max(output.data, dim=1)\n",
        "        \n",
        "        total += test_labels[key].shape[0]\n",
        "        correct += (predicted == test_labels[key]).sum()\n",
        "\n",
        "    each_task_acc = np.hstack((each_task_acc, np.array([correct.cpu().numpy()*100/total])))\n",
        "        \n",
        "print(each_task_acc)\n",
        "msg = 'Average accuracy after training task %d: %d %%\\n' % (task+1, np.mean(each_task_acc))\n",
        "print(msg)\n",
        "log_file.write(msg)\n",
        "avg_acc[task+1] = np.mean(each_task_acc)\n",
        "    \n",
        "log_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}